"""
å‘é‡æ•°æ®åº“æœåŠ¡
"""

import logging
import json
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncio
import numpy as np

import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
import httpx

from app.core.config import settings

logger = logging.getLogger(__name__)

class VectorDBService:
    """å‘é‡æ•°æ®åº“æœåŠ¡"""
    
    def __init__(self):
        self.client = None
        self.collection = None
        self.embedding_function = None
        
    async def init(self):
        """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
        try:
            # ç­‰å¾…å¹¶é‡è¯•è¿æ¥ Chroma æœåŠ¡ï¼Œé¿å…å®¹å™¨å°šæœªå°±ç»ªå¯¼è‡´è¿æ¥æ‹’ç»
            max_attempts = 10
            for attempt in range(1, max_attempts + 1):
                try:
                    # ä½¿ç”¨ HttpClientï¼ˆä¸ chromadb==0.4.18 æœåŠ¡ç«¯å…¼å®¹ï¼‰
                    self.client = chromadb.HttpClient(
                        host=settings.CHROMA_HOST,
                        port=settings.CHROMA_PORT,
                        settings=Settings(
                            anonymized_telemetry=False,
                            allow_reset=True,
                        ),
                    )
                    # è§¦å‘ä¸€æ¬¡ç®€å•è°ƒç”¨ä»¥éªŒè¯è¿æ¥
                    _ = self.client.list_collections()
                    break
                except Exception as conn_err:
                    if attempt == max_attempts:
                        raise conn_err
                    logger.warning(f"Chromaæœªå°±ç»ªï¼Œé‡è¯•({attempt}/{max_attempts})... é”™è¯¯: {conn_err}")
                    await asyncio.sleep(1.0)
            
            # åˆå§‹åŒ–åµŒå…¥å‡½æ•°ï¼ˆä¼˜å…ˆï¼šOpenAI -> MiniMax -> æœ¬åœ°ï¼‰ï¼Œå¹¶è¿›è¡Œæ¢é’ˆæ ¡éªŒï¼›å¤±è´¥åˆ™å›é€€åˆ°æœ¬åœ°
            def _probe_embedding(func) -> bool:
                try:
                    _ = func(["embedding_probe"])
                    return True
                except Exception as e:
                    logger.warning(f"åµŒå…¥æ¢é’ˆå¤±è´¥ï¼Œå°†å›é€€ï¼š{e}")
                    return False

            selected = None
            # ä¼˜å…ˆä½¿ç”¨ OpenAIï¼ˆå¤šè¯­è¨€æ¨¡å‹ï¼‰
            if settings.OPENAI_API_KEY:
                try:
                    candidate = embedding_functions.OpenAIEmbeddingFunction(
                        api_key=settings.OPENAI_API_KEY,
                        model_name="text-embedding-3-small"
                    )
                    if _probe_embedding(candidate):
                        selected = candidate
                        logger.info("âœ… ä½¿ç”¨ OpenAI Embeddings (text-embedding-3-small)")
                except Exception as e:
                    logger.warning(f"OpenAIåµŒå…¥åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
            # å…¶æ¬¡ä½¿ç”¨ MiniMax
            if (not selected) and settings.MINIMAX_API_KEY and settings.MINIMAX_GROUP_ID:
                try:
                    class MiniMaxEmbeddingFunction:
                        def __init__(self, api_key: str, group_id: str, base_url: str = "https://api.minimax.chat/v1", model: str = "embedding-1"):
                            self.api_key = api_key
                            self.group_id = group_id
                            self.base_url = base_url
                            self.model = model

                        def __call__(self, texts):
                            headers = {
                                "Authorization": f"Bearer {self.api_key}",
                                "Content-Type": "application/json",
                            }
                            payload = {"model": self.model, "texts": list(texts)}
                            with httpx.Client(timeout=30) as client:
                                resp = client.post(f"{self.base_url}/embeddings", headers=headers, json=payload, params={"GroupId": self.group_id})
                                resp.raise_for_status()
                                data = resp.json()
                                return [item.get("embedding") or item.get("vector") for item in data.get("data", [])]
                    candidate = MiniMaxEmbeddingFunction(
                        api_key=settings.MINIMAX_API_KEY,
                        group_id=settings.MINIMAX_GROUP_ID,
                    )
                    if _probe_embedding(candidate):
                        selected = candidate
                        logger.info("âœ… ä½¿ç”¨ MiniMax Embeddings")
                except Exception as e:
                    logger.warning(f"MiniMaxåµŒå…¥åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
            # å›é€€åˆ°æœ¬åœ° Sentence-Transformersï¼ˆä¸­æ–‡å‹å¥½æ¨¡å‹ï¼‰
            if not selected:
                try:
                    selected = embedding_functions.SentenceTransformerEmbeddingFunction(
                        model_name="paraphrase-multilingual-MiniLM-L12-v2"
                    )
                    # æœ¬åœ°æ¨¡å‹æ— éœ€æ¢é’ˆ
                    logger.info("âœ… ä½¿ç”¨æœ¬åœ° Sentence-Transformers (paraphrase-multilingual-MiniLM-L12-v2)")
                except Exception as e:
                    logger.warning(f"æœ¬åœ°åµŒå…¥åˆå§‹åŒ–å¤±è´¥ï¼š{e}")
                    selected = None
            self.embedding_function = selected
            
            # åˆ›å»ºæˆ–è·å–é›†åˆ
            # åˆ›å»ºæˆ–è·å–é›†åˆï¼ˆå…è®¸æ— åµŒå…¥å‡½æ•°ï¼Œä»¥ä¿è¯åˆå§‹åŒ–æˆåŠŸï¼‰
            self.collection = self.client.get_or_create_collection(
                name="bank_knowledge",
                embedding_function=self.embedding_function,
                metadata={"description": "é“¶è¡Œä¸šåŠ¡çŸ¥è¯†åº“"}
            )
            
            logger.info("âœ… å‘é‡æ•°æ®åº“åˆå§‹åŒ–æˆåŠŸ")

            # åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆè‹¥æ— åµŒå…¥å‡½æ•°ï¼Œåˆ™ä»…è·³è¿‡æ•°æ®å†™å…¥ï¼Œé¿å…å¤±è´¥ï¼‰
            if self.embedding_function:
                await self._init_knowledge_base()
            else:
                logger.info("å·²è·³è¿‡çŸ¥è¯†åº“åˆå§‹æ•°æ®å†™å…¥ï¼šæœªé…ç½®åµŒå…¥å‡½æ•°ã€‚")
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def _init_knowledge_base(self):
        """åˆå§‹åŒ–çŸ¥è¯†åº“ï¼ˆå¢é‡å†™å…¥ï¼Œä¸è¦†ç›–å·²æœ‰æ•°æ®ï¼‰"""
        try:
            # åŠ è½½åŸºç¡€çŸ¥è¯†æ•°æ®
            seed_data = self._get_knowledge_data()

            # è·å–ç°æœ‰æ–‡æ¡£ç”¨äºå»é‡
            existing_docs = []
            try:
                if self.collection:
                    all_docs = self.collection.get()
                    existing_docs = list(all_docs.get("documents", []) or [])
            except Exception as _e:
                logger.debug(f"è¯»å–ç°æœ‰çŸ¥è¯†åº“å¤±è´¥ï¼Œè§†ä¸ºç©ºé›†åˆ: {_e}")

            existing_set = set(existing_docs)

            # é€‰æ‹©æœªå­˜åœ¨çš„æ–°å¢æ•°æ®
            to_add = [item for item in seed_data if item.get("content") not in existing_set]
            if not to_add:
                logger.info("ğŸ“š çŸ¥è¯†åº“å·²åŒ…å«æ‰€æœ‰æ¼”ç¤ºFAQï¼Œæ— éœ€æ–°å¢ã€‚")
                return

            documents = []
            metadatas = []
            ids = []

            base_idx = len(existing_docs)
            for i, item in enumerate(to_add):
                documents.append(item["content"])
                metadatas.append({
                    "category": item["category"],
                    "keywords": json.dumps(item["keywords"]),
                    "created_at": datetime.now().isoformat()
                })
                ids.append(f"doc_{base_idx + i}")

            self.collection.add(
                documents=documents,
                metadatas=metadatas,
                ids=ids
            )

            logger.info(f"âœ… çŸ¥è¯†åº“å¢é‡åˆå§‹åŒ–å®Œæˆï¼Œæ–°å¢ {len(to_add)} æ¡æ–‡æ¡£ï¼Œæ€»è®¡ {len(existing_docs) + len(to_add)} æ¡")

        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _get_knowledge_data(self) -> List[Dict[str, Any]]:
        """è·å–åŸºç¡€çŸ¥è¯†æ•°æ®"""
        return [
            {
                "content": "å‚¨è“„è´¦æˆ·æ˜¯é“¶è¡Œä¸ºå®¢æˆ·æä¾›çš„æœ€åŸºæœ¬è´¦æˆ·ç±»å‹ï¼Œå¯ä»¥è¿›è¡Œå­˜å–æ¬¾ã€è½¬è´¦ç­‰æ“ä½œã€‚å‚¨è“„è´¦æˆ·é€šå¸¸æ²¡æœ‰æœ€ä½ä½™é¢è¦æ±‚ï¼Œé€‚åˆæ—¥å¸¸èµ„é‡‘ç®¡ç†ã€‚",
                "category": "è´¦æˆ·ç®¡ç†",
                "keywords": ["å‚¨è“„è´¦æˆ·", "å­˜å–æ¬¾", "è½¬è´¦", "åŸºæœ¬è´¦æˆ·", "savings account", "deposit", "transfer"]
            },
            {
                "content": "è½¬è´¦æ˜¯é“¶è¡Œå®¢æˆ·ä¹‹é—´è¿›è¡Œèµ„é‡‘è½¬ç§»çš„æœåŠ¡ã€‚å¯ä»¥é€šè¿‡ç½‘é“¶ã€æ‰‹æœºé“¶è¡Œæˆ–æŸœå°è¿›è¡Œè½¬è´¦ã€‚è½¬è´¦æ—¶éœ€è¦æä¾›æ”¶æ¬¾äººå§“åã€è´¦å·å’Œå¼€æˆ·è¡Œä¿¡æ¯ã€‚",
                "category": "è½¬è´¦æœåŠ¡",
                "keywords": ["è½¬è´¦", "èµ„é‡‘è½¬ç§»", "ç½‘é“¶", "æ‰‹æœºé“¶è¡Œ", "æ”¶æ¬¾äºº", "transfer", "bank transfer", "wire"]
            },
            {
                "content": "åœ¨çº¿è½¬è´¦æµç¨‹ï¼š1ï¼‰ç™»å½•ç½‘é“¶æˆ–æ‰‹æœºé“¶è¡Œ 2ï¼‰è¿›å…¥è½¬è´¦/æ±‡æ¬¾ 3ï¼‰å¡«å†™æ”¶æ¬¾äººå§“åã€è´¦å·ã€å¼€æˆ·è¡Œ 4ï¼‰è¾“å…¥é‡‘é¢ä¸å¤‡æ³¨ 5ï¼‰ç¡®è®¤å¹¶è¿›è¡Œå®‰å…¨éªŒè¯ï¼ˆçŸ­ä¿¡/æŒ‡çº¹/äººè„¸ï¼‰ 6ï¼‰æäº¤è½¬è´¦ï¼Œç­‰å¾…æˆåŠŸæç¤ºã€‚",
                "category": "è½¬è´¦æµç¨‹",
                "keywords": ["è½¬è´¦æµç¨‹", "å¦‚ä½•è½¬è´¦", "online transfer", "how to transfer", "æ±‡æ¬¾æ­¥éª¤"]
            },
            {
                "content": "ç†è´¢äº§å“ç±»å‹ä¸é€‚é…ï¼šç¨³å¥å‹ï¼ˆè´§å¸/å€ºåˆ¸åŸºé‡‘ï¼Œä½é£é™©ã€é€‚åˆä¿å€¼ï¼‰ï¼›å¹³è¡¡å‹ï¼ˆæ··åˆåŸºé‡‘ï¼Œé£é™©ä¸­ç­‰ã€å…¼é¡¾æ”¶ç›Šï¼‰ï¼›è¿›å–å‹ï¼ˆè‚¡ç¥¨/æŒ‡æ•°åŸºé‡‘ï¼Œä¸­é«˜é£é™©ã€è¿½æ±‚æ›´é«˜æ”¶ç›Šï¼‰ã€‚æ ¹æ®é£é™©åå¥½ä¸æŒæœ‰æœŸé™é€‰æ‹©ã€‚",
                "category": "ç†è´¢äº§å“",
                "keywords": ["ç†è´¢äº§å“", "äº§å“æ¨è", "æ¨èçš„ç†è´¢äº§å“", "é£é™©åå¥½", "æŠ•èµ„å»ºè®®", "investment products", "risk profile"]
            },
            {
                "content": "æ¨èç†è´¢äº§å“ï¼šè‹¥é£é™©åå¥½ä¸ºç¨³å¥ä¸”èµ„é‡‘ä½¿ç”¨å‘¨æœŸçŸ­ï¼Œå»ºè®®è´§å¸åŸºé‡‘æˆ–çŸ­å€ºåŸºé‡‘ï¼›è‹¥å¯æ‰¿å—ä¸­ç­‰æ³¢åŠ¨ä¸”å‘¨æœŸä¸€å¹´ä»¥ä¸Šï¼Œå»ºè®®å€ºåˆ¸/æ··åˆåŸºé‡‘ï¼›è‹¥è¿½æ±‚æˆé•¿ã€å‘¨æœŸä¸‰å¹´ä»¥ä¸Šï¼Œå»ºè®®æŒ‡æ•°åŸºé‡‘æˆ–ä¼˜é€‰è‚¡ç¥¨åŸºé‡‘ã€‚",
                "category": "ç†è´¢æ¨è",
                "keywords": ["æ¨èç†è´¢", "ç¨³å¥å‹", "å¹³è¡¡å‹", "è¿›å–å‹", "investment recommendation"]
            },
            {
                "content": "ç”³è¯·è´·æ¬¾æµç¨‹ï¼š1ï¼‰ç¡®è®¤è´·æ¬¾ç±»å‹ä¸é¢åº¦éœ€æ±‚ 2ï¼‰å‡†å¤‡ææ–™ï¼ˆèº«ä»½è¯ã€æ”¶å…¥/èµ„äº§è¯æ˜ã€å¾ä¿¡æˆæƒç­‰ï¼‰ 3ï¼‰æäº¤çº¿ä¸Šç”³è¯·æˆ–åˆ°æŸœå°åŠç† 4ï¼‰èµ„è´¨å®¡æ ¸ä¸é£æ§è¯„ä¼° 5ï¼‰ç­¾ç½²åˆåŒä¸æŠµæŠ¼/æ‹…ä¿æ‰‹ç»­ 6ï¼‰æ”¾æ¬¾ä¸è¿˜æ¬¾è®¡åˆ’ã€‚",
                "category": "è´·æ¬¾æµç¨‹",
                "keywords": ["ç”³è¯·è´·æ¬¾", "è´·æ¬¾æµç¨‹", "è´·æ¬¾ææ–™", "å®¡æ‰¹", "loan application", "apply for loan"]
            },
            {
                "content": "è´·æ¬¾ææ–™æ¸…å•ï¼šèº«ä»½è¯æ˜ã€å·¥ä½œä¸æ”¶å…¥è¯æ˜ã€è¿‘6ä¸ªæœˆé“¶è¡Œæµæ°´ã€èµ„äº§ä¸è´Ÿå€ºæƒ…å†µã€ä¿¡ç”¨æŠ¥å‘Šæˆæƒã€æˆ¿äº§æˆ–è½¦è¾†ç›¸å…³ææ–™ï¼ˆå¦‚æŠµæŠ¼ï¼‰ã€‚å…·ä½“ä»¥è´·æ¬¾ç±»å‹ä¸åœ°åŒºæ”¿ç­–ä¸ºå‡†ã€‚",
                "category": "è´·æ¬¾æœåŠ¡",
                "keywords": ["è´·æ¬¾ææ–™", "æ”¶å…¥è¯æ˜", "å¾ä¿¡", "æŠµæŠ¼", "loan documents"]
            },
            {
                "content": "å½“å‰è´¦æˆ·ç†è´¢å»ºè®®ï¼šå»ºè®®å…ˆä¿ç•™3-6ä¸ªæœˆç”Ÿæ´»åº”æ€¥é‡‘äºæ´»æœŸ/è´§å¸åŸºé‡‘ï¼›å‰©ä½™èµ„é‡‘æ ¹æ®é£é™©åå¥½åˆ†é…ï¼šç¨³å¥å‹åå€º/è´§åŸºï¼Œå¹³è¡¡å‹åæ··åˆï¼Œè¿›å–å‹åæŒ‡æ•°/è‚¡ç¥¨ã€‚å»ºè®®å®šæŠ•ä¸åˆ†æ•£é…ç½®ä»¥é™ä½æ³¢åŠ¨ã€‚",
                "category": "ç†è´¢å»ºè®®",
                "keywords": ["ç†è´¢å»ºè®®", "å½“å‰è´¦æˆ·çš„ç†è´¢å»ºè®®", "è´¦æˆ·å»ºè®®", "èµ„äº§é…ç½®", "å®šæŠ•", "investment advice", "asset allocation"]
            },
            {
                "content": "æ¨èçš„ç†è´¢äº§å“ï¼šç»“åˆé£é™©æµ‹è¯„ä¸æŠ•èµ„æœŸé™ï¼Œç¨³å¥åå¥½å»ºè®®è´§åŸº/çŸ­å€ºï¼›ä¸€å¹´ä»¥ä¸Šå¯è€ƒè™‘å€ºåˆ¸/æ··åˆï¼›ä¸‰å¹´ä»¥ä¸Šå¯è€ƒè™‘æŒ‡æ•°/è‚¡ç¥¨ã€‚é€‰æ‹©æ—¶é‡ç‚¹å…³æ³¨é£é™©ç­‰çº§ã€æµåŠ¨æ€§ä¸å†å²å›æ’¤ã€‚",
                "category": "ç†è´¢æ¨è",
                "keywords": ["æ¨èçš„ç†è´¢äº§å“", "ç†è´¢æ¨è", "äº§å“ç­›é€‰", "é£é™©ç­‰çº§", "investment recommendation"]
            },
            {
                "content": "å½“å‰è´¦æˆ·çš„ç†è´¢å»ºè®®ï¼šåœ¨ä¿è¯åº”æ€¥é‡‘çš„å‰æä¸‹ï¼Œæ ¹æ®è´¦æˆ·ä½™é¢ä¸ç›®æ ‡æ”¶ç›Šè®¾å®šåˆ†æ•£é…ç½®æ¯”ä¾‹ï¼Œå¹¶é‡‡ç”¨å®šæŠ•ç­–ç•¥å‡å°‘æ‹©æ—¶é£é™©ï¼›å®šæœŸå¤ç›˜å¹¶æ ¹æ®å¸‚åœºä¸ä¸ªäººæƒ…å†µè°ƒæ•´ã€‚",
                "category": "ç†è´¢å»ºè®®",
                "keywords": ["å½“å‰è´¦æˆ·çš„ç†è´¢å»ºè®®", "ç†è´¢å»ºè®®", "è´¦æˆ·å»ºè®®", "å®šæŠ•", "asset allocation", "investment advice"]
            },
            {
                "content": "è´­ä¹°ç†è´¢äº§å“æµç¨‹ï¼š1ï¼‰ç™»å½•ç½‘é“¶æˆ–æ‰‹æœºé“¶è¡Œ 2ï¼‰è¿›å…¥ç†è´¢/æŠ•èµ„ä¸“åŒº 3ï¼‰ç­›é€‰äº§å“ï¼ˆé£é™©ç­‰çº§ã€æœŸé™ã€å†å²å›æŠ¥ï¼‰ 4ï¼‰æŸ¥çœ‹äº§å“è¯´æ˜ä¹¦ä¸é£é™©æ­ç¤º 5ï¼‰è¾“å…¥è´­ä¹°é‡‘é¢å¹¶è¿›è¡Œé£é™©æµ‹è¯„ 6ï¼‰ç¡®è®¤è´­ä¹°ã€‚",
                "category": "ç†è´¢æµç¨‹",
                "keywords": ["è´­ä¹°ç†è´¢", "ç†è´¢æµç¨‹", "äº§å“è¯´æ˜ä¹¦", "é£é™©æµ‹è¯„", "buy investment"]
            },
            {
                "content": "ä¸ªäººæ¶ˆè´¹è´·æ¬¾ç®€ä»‹ï¼šç”¨äºæ¶ˆè´¹ç”¨é€”çš„è´·æ¬¾ï¼Œé¢åº¦ä¸åˆ©ç‡æ ¹æ®ä¸ªäººèµ„è´¨è¯„ä¼°ã€‚è¿˜æ¬¾æ–¹å¼åŒ…æ‹¬ç­‰é¢æœ¬æ¯ä¸ç­‰é¢æœ¬é‡‘ã€‚æå‰è¿˜æ¬¾å¯èƒ½æ¶‰åŠè¿çº¦é‡‘æˆ–æ‰‹ç»­è´¹ï¼Œå…·ä½“ä»¥åˆåŒä¸ºå‡†ã€‚",
                "category": "è´·æ¬¾æœåŠ¡",
                "keywords": ["æ¶ˆè´¹è´·æ¬¾", "åˆ©ç‡", "è¿˜æ¬¾", "æå‰è¿˜æ¬¾", "personal loan"]
            },
            {
                "content": "é“¶è¡Œå¡æŒ‚å¤±ä¸è¡¥åŠï¼šè‹¥é“¶è¡Œå¡é—å¤±æˆ–è¢«ç›—ï¼Œç«‹å³é€šè¿‡å®¢æœçƒ­çº¿æˆ–æ‰‹æœºé“¶è¡Œè¿›è¡ŒæŒ‚å¤±ï¼›æºå¸¦èº«ä»½è¯ä»¶åˆ°ç½‘ç‚¹åŠç†è¡¥å¡ä¸å¯†ç é‡ç½®ï¼Œå»ºè®®åŒæ­¥ä¿®æ”¹ç½‘é“¶ç™»å½•å¯†ç ã€‚",
                "category": "å®‰å…¨æŒ‡å—",
                "keywords": ["æŒ‚å¤±", "è¡¥å¡", "å¯†ç é‡ç½®", "é“¶è¡Œå¡ä¸¢å¤±", "card lost"]
            },
            {
                "content": "é“¶è¡ŒæœåŠ¡æ—¶é—´ï¼šæŸœå°æœåŠ¡ä¸€èˆ¬ä¸ºå·¥ä½œæ—¥9:00-17:00ï¼Œå‘¨æœ«éƒ¨åˆ†ç½‘ç‚¹è¥ä¸šã€‚ATMæœº24å°æ—¶æœåŠ¡ã€‚ç½‘é“¶å’Œæ‰‹æœºé“¶è¡Œå…¨å¤©å€™æœåŠ¡ã€‚",
                "category": "æœåŠ¡æ—¶é—´",
                "keywords": ["æœåŠ¡æ—¶é—´", "æŸœå°", "ATM", "ç½‘é“¶", "æ‰‹æœºé“¶è¡Œ", "è¥ä¸šæ—¶é—´", "service hours"]
            },
            {
                "content": "åˆ©æ¯è®¡ç®—ï¼šå‚¨è“„å­˜æ¬¾æŒ‰å¹´åˆ©ç‡è®¡ç®—ï¼Œæ´»æœŸå­˜æ¬¾æŒ‰æ—¥è®¡æ¯ï¼Œå®šæœŸå­˜æ¬¾æŒ‰å­˜æœŸè®¡æ¯ã€‚è´·æ¬¾åˆ©ç‡æŒ‰å¹´åˆ©ç‡è®¡ç®—ï¼Œåˆ†ä¸ºå›ºå®šåˆ©ç‡å’Œæµ®åŠ¨åˆ©ç‡ã€‚",
                "category": "åˆ©æ¯è®¡ç®—",
                "keywords": ["åˆ©æ¯", "å¹´åˆ©ç‡", "æ´»æœŸ", "å®šæœŸ", "è´·æ¬¾åˆ©ç‡", "å›ºå®šåˆ©ç‡", "æµ®åŠ¨åˆ©ç‡", "interest", "APR"]
            },
            {
                "content": "æ‰‹ç»­è´¹ä¸è´¹ç”¨ï¼šè·¨è¡Œè½¬è´¦å¯èƒ½æ”¶å–æ‰‹ç»­è´¹ï¼›ä¿¡ç”¨å¡å–ç°é€šå¸¸æœ‰æ‰‹ç»­è´¹ä¸åˆ©æ¯ï¼›éƒ¨åˆ†ç†è´¢äº§å“æœ‰ç”³è´­/èµå›è´¹ç”¨ã€‚è¯·åœ¨åŠç†å‰æŸ¥çœ‹è´¹ç”¨æ ‡å‡†ä¸å…¬å‘Šã€‚",
                "category": "è´¹ç”¨è¯´æ˜",
                "keywords": ["æ‰‹ç»­è´¹", "è´¹ç”¨", "å–ç°", "ç”³è´­è´¹", "èµå›è´¹", "fees"]
            },
            {
                "content": "å¤–å¸å…‘æ¢ä¸ç»“å”®æ±‡ï¼šå¯åœ¨æŒ‡å®šç½‘ç‚¹æˆ–çº¿ä¸Šé¢„çº¦åŠç†ï¼Œéœ€æä¾›èº«ä»½è¯ä»¶ã€‚æ±‡ç‡éšå¸‚åœºå˜åŠ¨ï¼ŒåŠç†æ—¶ä»¥å½“æ—¥ç‰Œä»·ä¸ºå‡†ã€‚éƒ¨åˆ†å…‘æ¢å¯èƒ½éœ€è¦ç”¨é€”è¯´æ˜ä¸åˆè§„ææ–™ã€‚",
                "category": "å¤–æ±‡æœåŠ¡",
                "keywords": ["å¤–å¸å…‘æ¢", "ç»“å”®æ±‡", "æ±‡ç‡", "å¤–æ±‡", "FX", "currency exchange"]
            }
        ]
    
    async def search_knowledge(self, query: str, limit: int = 5) -> List[Dict[str, Any]]:
        """æœç´¢çŸ¥è¯†åº“"""
        try:
            if not self.collection or not self.embedding_function:
                logger.warning("æŸ¥è¯¢è¢«è·³è¿‡ï¼šå‘é‡é›†åˆæˆ–åµŒå…¥å‡½æ•°æœªåˆå§‹åŒ–ã€‚")
                return []
            def _expand(q: str) -> List[str]:
                qn = (q or "").strip().lower()
                expansions = [q]
                # å¸¸è§é“¶è¡ŒåŒä¹‰è¯æ‰©å±•ï¼ˆä¸­è‹±æ··åˆï¼‰
                synonyms_map = {
                    "è½¬è´¦": ["è½¬è´¦", "æ±‡æ¬¾", "è½¬è´¦æµç¨‹", "online transfer", "bank transfer", "wire"],
                    "è´·æ¬¾": ["è´·æ¬¾", "ç”³è¯·è´·æ¬¾", "è´·æ¬¾æµç¨‹", "apply for loan", "loan application"],
                    "ç†è´¢": ["ç†è´¢", "ç†è´¢äº§å“", "æ¨èçš„ç†è´¢äº§å“", "investment products", "investment recommendation"],
                    "èµ„äº§é…ç½®": ["èµ„äº§é…ç½®", "ç†è´¢å»ºè®®", "å½“å‰è´¦æˆ·çš„ç†è´¢å»ºè®®", "asset allocation", "investment advice"],
                }
                for key, syns in synonyms_map.items():
                    if key in qn:
                        expansions.extend(syns)
                # å»é‡
                seen = set()
                uniq = []
                for e in expansions:
                    if e and e not in seen:
                        seen.add(e)
                        uniq.append(e)
                return uniq

            expanded_queries = _expand(query)
            results = None
            for idx, q in enumerate(expanded_queries):
                results = self.collection.query(
                    query_texts=[q],
                    n_results=limit,
                    include=["documents", "metadatas", "distances"]
                )
                if results and results.get("documents") and results["documents"] and results["documents"][0]:
                    if idx > 0:
                        logger.info(f"ğŸ” åŸå§‹æŸ¥è¯¢æ— ç»“æœï¼Œä½¿ç”¨æ‰©å±•è¯ '{q}' å‘½ä¸­ {len(results['documents'][0])} æ¡")
                    break
            try:
                # è¿½åŠ è°ƒè¯•æ—¥å¿—ï¼Œå¸®åŠ©å®šä½è¿”å›ç»“æ„
                logger.debug(f"ChromaåŸå§‹è¿”å›: keys={list(results.keys())}; sizes={{'documents': len(results.get('documents', [])) if isinstance(results.get('documents'), list) else 'n/a', 'metadatas': len(results.get('metadatas', [])) if isinstance(results.get('metadatas'), list) else 'n/a', 'distances': len(results.get('distances', [])) if isinstance(results.get('distances'), list) else 'n/a'}}")
            except Exception:
                pass
            if not results or not results.get("documents") or not results["documents"]:
                # å‘é‡æ£€ç´¢ä¸ºç©ºæ—¶ï¼Œå°è¯•ä½¿ç”¨æœ¬åœ°åµŒå…¥è¿›è¡Œä½™å¼¦ç›¸ä¼¼åº¦é‡æ’ï¼ˆæ— éœ€ä¾èµ–Chromaç´¢å¼•ï¼‰
                try:
                    all_docs = self.collection.get()
                    docs = all_docs.get("documents", []) or []
                    metas = all_docs.get("metadatas", []) or []
                    ids = all_docs.get("ids", []) or []
                    if docs and self.embedding_function:
                        qe = self.embedding_function([str(query)])
                        if qe and len(qe) > 0:
                            qv = np.array(qe[0], dtype=float)
                            dv = self.embedding_function(docs)
                            scores = []
                            for i, emb in enumerate(dv):
                                v = np.array(emb, dtype=float)
                                # ä½™å¼¦è·ç¦» = 1 - ä½™å¼¦ç›¸ä¼¼åº¦
                                denom = (np.linalg.norm(qv) * np.linalg.norm(v))
                                dist = 1.0 - float(np.dot(qv, v) / denom) if denom > 0 else 1.0
                                scores.append((dist, i))
                            # å–æœ€å°è·ç¦»çš„å‰Nä¸ª
                            scores.sort(key=lambda x: x[0])
                            top = scores[:limit]
                            formatted = [{
                                "content": docs[j],
                                "metadata": metas[j] if j < len(metas) else {},
                                "distance": top_dist,
                                "id": ids[j] if j < len(ids) else None
                            } for (top_dist, j) in top]
                            logger.info(f"ğŸ” å‘é‡æ£€ç´¢ä¸ºç©ºï¼Œä½¿ç”¨æœ¬åœ°åµŒå…¥é‡æ’è¿”å› {len(formatted)} æ¡")
                            return formatted
                except Exception as _e:
                    logger.debug(f"æœ¬åœ°åµŒå…¥é‡æ’å¤±è´¥: {_e}")

                # è‹¥æœ¬åœ°é‡æ’ä¹Ÿä¸å¯ç”¨ï¼Œåˆ™é€€å›åˆ°å…³é”®å­—/å…¨æ–‡åŒ¹é…
                try:
                    all_docs = self.collection.get()
                    fallback = []
                    docs = all_docs.get("documents", []) or []
                    metas = all_docs.get("metadatas", []) or []
                    ids = all_docs.get("ids", []) or []
                    q = str(query).strip()
                    # ç®€å•åˆ†è¯å‡½æ•°ï¼šæŒ‰ç©ºæ ¼ä¸å¸¸è§ä¸­æ–‡æ ‡ç‚¹åˆ†å‰²
                    def tokenize(text: str) -> List[str]:
                        if not text:
                            return []
                        seps = " ï¼Œã€‚ï¼ï¼Ÿï¼›ã€:ï¼š;,.!?\n\t"
                        t = "".join([c if c not in seps else " " for c in text])
                        return [w for w in t.split(" ") if w]
                    q_tokens = set(tokenize(q))
                    for i, doc in enumerate(docs):
                        meta = metas[i] if i < len(metas) else {}
                        kw_raw = meta.get("keywords")
                        kw_list = []
                        if isinstance(kw_raw, str):
                            try:
                                kw_list = json.loads(kw_raw)
                            except Exception:
                                kw_list = [kw_raw]
                        elif isinstance(kw_raw, list):
                            kw_list = kw_raw
                        cond = (q and q in (doc or "")) or any(q and q in str(k) for k in kw_list)
                        if cond:
                            d_tokens = set(tokenize(doc or ""))
                            inter = len(q_tokens.intersection(d_tokens))
                            union = len(q_tokens.union(d_tokens)) or 1
                            jaccard = inter / union
                            # å°†è·ç¦»å½’ä¸€åŒ–ä¸º [0,1] çš„å€¼
                            dist = float(1.0 - jaccard)
                            fallback.append({
                                "content": doc,
                                "metadata": meta,
                                "distance": dist,
                                "id": ids[i] if i < len(ids) else None
                            })
                    if fallback:
                        logger.info(f"ğŸ” ä½¿ç”¨å…³é”®è¯é‡æ’è¿”å› {len(fallback)} æ¡")
                        return fallback[:limit]
                except Exception as _e:
                    logger.debug(f"å…³é”®è¯é‡æ’å¤±è´¥: {_e}")
                logger.info(f"ğŸ” çŸ¥è¯†åº“æœç´¢å®Œæˆï¼ŒæŸ¥è¯¢: '{query}', ç»“æœæ•°: 0")
                return []
            
            # æ ¼å¼åŒ–ç»“æœ
            formatted_results = []
            for i, doc in enumerate(results["documents"][0]):
                formatted_results.append({
                    "content": doc,
                    "metadata": results["metadatas"][0][i],
                    "distance": results["distances"][0][i],
                    "id": results["ids"][0][i]
                })
            
            logger.info(f"ğŸ” çŸ¥è¯†åº“æœç´¢å®Œæˆï¼ŒæŸ¥è¯¢: '{query}', ç»“æœæ•°: {len(formatted_results)}")
            return formatted_results

        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†åº“æœç´¢å¤±è´¥: {e}")
            return []

    async def rebuild_embeddings(self) -> bool:
        """é‡å»ºå½“å‰é›†åˆåµŒå…¥ï¼šè¯»å–æ‰€æœ‰æ–‡æ¡£ï¼Œåˆ é™¤é›†åˆå¹¶ä½¿ç”¨å½“å‰åµŒå…¥å‡½æ•°é‡å»ºã€‚
        é€‚ç”¨äºåˆ‡æ¢åµŒå…¥æ¨¡å‹åå¯¼è‡´æŸ¥è¯¢ç©ºé—´ä¸ä¸€è‡´çš„æƒ…å†µã€‚
        """
        try:
            if not self.client:
                logger.warning("é‡å»ºè·³è¿‡ï¼šChromaå®¢æˆ·ç«¯æœªåˆå§‹åŒ–ã€‚")
                return False
            # è¯»å–ç°æœ‰æ–‡æ¡£
            docs_all = None
            try:
                docs_all = self.collection.get()
            except Exception as e:
                logger.warning(f"è¯»å–ç°æœ‰é›†åˆå¤±è´¥ï¼Œå°†æ‰§è¡Œç©ºé‡å»º: {e}")
            documents = list((docs_all or {}).get("documents", []) or [])
            metadatas = list((docs_all or {}).get("metadatas", []) or [])
            ids = list((docs_all or {}).get("ids", []) or [])

            # åˆ é™¤å¹¶é‡å»ºé›†åˆ
            try:
                self.client.delete_collection(name="bank_knowledge")
                logger.info("ğŸ§¹ å·²åˆ é™¤æ—§é›†åˆ bank_knowledge")
            except Exception as e:
                logger.warning(f"åˆ é™¤é›†åˆå¤±è´¥æˆ–ä¸å­˜åœ¨: {e}")

            self.collection = self.client.get_or_create_collection(
                name="bank_knowledge",
                embedding_function=self.embedding_function,
                metadata={"description": "é“¶è¡Œä¸šåŠ¡çŸ¥è¯†åº“"}
            )
            logger.info("ğŸ“¦ å·²åˆ›å»ºæ–°é›†åˆ bank_knowledge å¹¶ç»‘å®šå½“å‰åµŒå…¥å‡½æ•°")

            # å›çŒæ–‡æ¡£
            if documents:
                self.collection.add(
                    documents=documents,
                    metadatas=metadatas,
                    ids=ids
                )
                logger.info(f"âœ… é‡å»ºå®Œæˆï¼Œå›çŒæ–‡æ¡£æ•°: {len(documents)}")
            else:
                # è‹¥ä¹‹å‰ä¸ºç©ºï¼Œåˆ™è¿›è¡Œç§å­æ•°æ®åˆå§‹åŒ–
                await self._init_knowledge_base()
                logger.info("âœ… é‡å»ºå®Œæˆï¼Œä½¿ç”¨ç§å­æ•°æ®åˆå§‹åŒ–é›†åˆ")
            return True
        except Exception as e:
            logger.error(f"âŒ é›†åˆé‡å»ºå¤±è´¥: {e}")
            return False
    
    async def add_knowledge(self, content: str, category: str, keywords: List[str]) -> bool:
        """æ·»åŠ çŸ¥è¯†"""
        try:
            if not self.collection:
                logger.warning("æ·»åŠ è¢«è·³è¿‡ï¼šå‘é‡é›†åˆæœªåˆå§‹åŒ–ã€‚")
                return False
            doc_id = f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            self.collection.add(
                documents=[content],
                metadatas=[{
                    "category": category,
                    "keywords": json.dumps(keywords),
                    "created_at": datetime.now().isoformat()
                }],
                ids=[doc_id]
            )
            
            logger.info(f"âœ… çŸ¥è¯†æ·»åŠ æˆåŠŸ: {doc_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ çŸ¥è¯†æ·»åŠ å¤±è´¥: {e}")
            return False
    
    async def get_collection_info(self) -> Dict[str, Any]:
        """è·å–é›†åˆä¿¡æ¯"""
        try:
            count = self.collection.count()
            
            # è·å–ç±»åˆ«ç»Ÿè®¡
            results = self.collection.get()
            categories = {}
            for metadata in results["metadatas"]:
                category = metadata.get("category", "æœªåˆ†ç±»")
                categories[category] = categories.get(category, 0) + 1
            
            return {
                "total_documents": count,
                "categories": categories,
                "collection_name": self.collection.name
            }
            
        except Exception as e:
            logger.error(f"âŒ è·å–é›†åˆä¿¡æ¯å¤±è´¥: {e}")
            return {}

# å…¨å±€å®ä¾‹
vector_db_service = VectorDBService()

async def init_vector_db():
    """åˆå§‹åŒ–å‘é‡æ•°æ®åº“"""
    await vector_db_service.init()